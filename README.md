# ğŸ¦™ Fine-tuning de LLaMA2 sur des textes mÃ©dicaux

Ce projet montre comment **affiner (fine-tuner)** le modÃ¨le de langage **LLaMA2** Ã  lâ€™aide de **Hugging Face Transformers** et **PEFT (LoRA)** afin dâ€™adapter un grand modÃ¨le prÃ©-entraÃ®nÃ© Ã  un domaine spÃ©cifique â€” ici, **le vocabulaire mÃ©dical**.

---

## ğŸ§  Objectif du projet

Lâ€™objectif de ce projet est de **spÃ©cialiser un modÃ¨le de langage de grande taille (LLM)** pour quâ€™il puisse mieux comprendre et rÃ©pondre Ã  des questions liÃ©es Ã  la mÃ©decine.  
Le fine-tuning a Ã©tÃ© rÃ©alisÃ© sur le jeu de donnÃ©es **`wiki_medical_terms_llam2_format`**.

Ce projet a une finalitÃ© **acadÃ©mique et expÃ©rimentale**, visant Ã  explorer les techniques modernes de fine-tuning, comme :
- la **quantification** (pour rÃ©duire la taille mÃ©moire),
- le **fine-tuning efficace en paramÃ¨tres (LoRA)**,
- et le **Supervised Fine-Tuning (SFT)**.

---

## ğŸ“‚ Structure du projet

```text
llama2-medical-finetune/
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ train.py # Script d'entraÃ®nement (fine-tuning)
â”‚ â”œâ”€â”€ inference.py # Script de gÃ©nÃ©ration de texte / test du modÃ¨le
â”‚ â””â”€â”€ utils.py # Fonctions utilitaires (tokenization, chargement du dataset)
â”œâ”€â”€ results/ # Checkpoints et journaux de logs
â”œâ”€â”€ requirements.txt # Liste des dÃ©pendances Python
â””â”€â”€ README.md # Documentation du projet
```

âš™ï¸ Installation et exÃ©cution
1ï¸âƒ£ Cloner le dÃ©pÃ´t
git clone https://github.com/Mojytgf/llama2-medical-finetune.git
cd llama2-medical-finetune

