# ğŸ¦™ Fine-tuning de LLaMA2 sur des textes mÃ©dicaux

Ce projet montre comment **affiner (fine-tuner)** le modÃ¨le de langage **LLaMA2** Ã  lâ€™aide de **Hugging Face Transformers** et **PEFT (LoRA)** afin dâ€™adapter un grand modÃ¨le prÃ©-entraÃ®nÃ© Ã  un domaine spÃ©cifique â€” ici, **le vocabulaire mÃ©dical**.

---

## ğŸ§  Objectif du projet

Lâ€™objectif de ce projet est de **spÃ©cialiser un modÃ¨le de langage de grande taille (LLM)** pour quâ€™il puisse mieux comprendre et rÃ©pondre Ã  des questions liÃ©es Ã  la mÃ©decine.  
Le fine-tuning a Ã©tÃ© rÃ©alisÃ© sur le jeu de donnÃ©es **`wiki_medical_terms_llam2_format`**.

Ce projet a une finalitÃ© **acadÃ©mique et expÃ©rimentale**, visant Ã  explorer les techniques modernes de fine-tuning, comme :
- la **quantification** (pour rÃ©duire la taille mÃ©moire),
- le **fine-tuning efficace en paramÃ¨tres (LoRA)**,
- et le **Supervised Fine-Tuning (SFT)**.

---

## ğŸ“‚ Structure du projet

```text
llama2-medical-finetune/
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ train.py # Script d'entraÃ®nement (fine-tuning)
â”‚ â”œâ”€â”€ inference.py # Script de gÃ©nÃ©ration de texte / test du modÃ¨le
â”‚ â””â”€â”€ utils.py # Fonctions utilitaires (tokenization, chargement du dataset)
â”œâ”€â”€ results/ # Checkpoints et journaux de logs
â”œâ”€â”€ requirements.txt # Liste des dÃ©pendances Python
â””â”€â”€ README.md # Documentation du projet
```

## âš™ï¸ Installation et exÃ©cution

### 1ï¸âƒ£ Cloner le dÃ©pÃ´t
bash
git clone https://github.com/Mojytgf/llama2-medical-finetune.git
cd llama2-medical-finetune

2ï¸âƒ£ Installer les dÃ©pendances

pip install -r requirements.txt

3ï¸âƒ£ Lancer le fine-tuning

python src/train.py

4ï¸âƒ£ Tester le modÃ¨le (infÃ©rence)

python src/inference.py

ğŸ’¬ Exemple dâ€™utilisation

Prompt :

Please tell me about Ascariasis

RÃ©ponse du modÃ¨le :

Lâ€™ascaridiose est une infection parasitaire causÃ©e par le ver rond Ascaris lumbricoides...

ğŸ“Š DÃ©tails dâ€™entraÃ®nement

  ModÃ¨le de base : aboonaji/llama2finetune-v2

  Jeu de donnÃ©es : aboonaji/wiki_medical_terms_llam2_format
 
  MÃ©thode : LoRA (Low-Rank Adaptation)

  PrÃ©cision : Quantification 4 bits (NF4)

  Librairies : Transformers, PEFT, TRL

  Nombre dâ€™Ã©tapes : 100 (version de dÃ©monstration)

Lâ€™entraÃ®nement a Ã©tÃ© effectuÃ© avec le SFTTrainer de trl, permettant un fine-tuning efficace avec une mÃ©moire GPU limitÃ©e.
ğŸ“ˆ RÃ©sultats et observations

Le modÃ¨le a appris Ã  mieux comprendre le vocabulaire mÃ©dical.

La quantification a permis dâ€™exÃ©cuter le fine-tuning sur du matÃ©riel limitÃ© (GPU Colab).

La perte (loss) a diminuÃ© progressivement, signe de convergence.

Les rÃ©ponses gÃ©nÃ©rÃ©es Ã©taient cohÃ©rentes et adaptÃ©es au contexte.

Exemple dâ€™Ã©volution de la perte :

  Step  10 â†’ Loss: 2.38  
  Step  50 â†’ Loss: 1.92  
  Step 100 â†’ Loss: 1.63

ğŸ§° Technologies utilisÃ©es

  ğŸ¤— Hugging Face Transformers

  ğŸ§® PEFT (LoRA)

  âš¡ BitsAndBytes (quantification 4 bits)

  ğŸ§  TRL (Supervised Fine-Tuning)

  ğŸ§° Python 3.10

  ğŸ“Š TensorBoard
